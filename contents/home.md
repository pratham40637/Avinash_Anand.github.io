

[![senli1073](https://img.shields.io/badge/senli1073-github-blue?logo=github)](https://github.com/senli1073)


Research Interests: Natural language processing, large language models (pre-training, alignment, and multilingual systems), multimodal LLMs for accident detection and medical imaging.
As my current focus is on building LLM pre-training pipelines—from kernel-level optimization
and ultrascale GPU parallelism to LLM algorithmic improvements like FlashAttention-4 and posttraining methods such as GRPO—my research centers on advancing Large Language Models and
multimodal generative AI. The aim is to design robust and efficient systems that integrate text and
vision for generalized reasoning and real-world applicability. My work spans LLM architecture, optimization, and task-specific model development, emphasizing multilingual, cross-lingual, and mathematical reasoning capabilities. I also explore multimodal mental health detection and vision-based
applications, such as road accident detection, traffic analysis, and maritime tracking. In general, my
goal is to build scalable and impactful AI systems that advance healthcare, transportation, and software engineering while meaningfully improving quality of life

#### Contact

Email: senli[at]fas.harvard.edu

#### Education
PhD Research Scholar, IIIT Delhi, India.
Thesis title: Multimodal Systems For Scientific and Educational Applications,
Courses: Large Language Models(LLMs), Natural Language Processing, Knowledge
Graphs, Collaborative Filtering, Data structures and algorithms, Information Retrieval,2021 - 2024.
B.E., Data Science and Big Data Technology, China University of Mining and Technology, 2018—2022.

#### Research Interests
Machine Learning for Seismology; Foundation Model; Observational Seismology; Microseismic Monitoring

